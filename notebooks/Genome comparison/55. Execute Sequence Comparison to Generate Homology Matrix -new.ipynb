{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Homology matrix generation from genome sequences\n",
    "\n",
    "In this notebook, I will be applying the notebooks accompanying the paper by Norsigian et al., 2020. (doi:10.1038/s41596-019-0254-3.) I will apply this for the P. thermo model we've been working on and the M10EXG strain that we used to validate our model with.\n",
    "\n",
    "This is the the first notebook in the tutorial to create homology matrix from genome sequences.There are four major steps in this notebook\n",
    "1. Download the genome annotation (GenBank files) from NCBI, and generate fasta files (protein &nucleotide) from them\n",
    "2. Perform BLASTp to find homologous proteins in strains of interest\n",
    "3. Use best bidirectional hits to create gene presence/absence matrix\n",
    "4. Supplementary for best practice: use BLASTn to check if we have missed any unannotated open reading frames and retain these genes in orthology matrix as well as guide future manual curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__ to be able to import the Entrez and SeqIO, I need to change the folder name from 'bio' to 'Bio' and then it'll work. \n",
    "\n",
    "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo\\Lib\\site-packages\n",
    "\n",
    "So be careful whenever i install Biopython again that this needs to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be working with strains in the faculative anaerobic clade of the genus. I will also add genomes that are obligate aerobes to see if that could highlight to us what changed between these species that made them become obligate aerobes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>NCBI ID</th>\n",
       "      <th>Physiology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goebacillus thermoglucosidasius M10EXG</td>\n",
       "      <td>2501416905</td>\n",
       "      <td>Facultative anaerobe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Strain     NCBI ID            Physiology\n",
       "0  Goebacillus thermoglucosidasius M10EXG  2501416905  Facultative anaerobe"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the information on the five strains we will be working with in this tutorial\n",
    "StrainsOfInterest=pd.read_excel('Strain Information.xlsx')\n",
    "StrainsOfInterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Reference Genome is as Described in the Base Reconstruction; here the reference is \n",
    "referenceStrainID='NCIMB11955'\n",
    "targetStrainIDs=list(StrainsOfInterest['NCBI ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download genome annotations (GenBank files) to generate fasta files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload genomes from NCBI\n",
    "Download the genome annotations (GenBank files) from NCBI for strains of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to download the annotated genebank files from NCBI\n",
    "def dl_genome(id, folder='genomes'): # be sure get CORRECT ID\n",
    "    files=glob('%s/*.gb'%folder)\n",
    "    out_file = '%s/%s.gb'%(folder, id)\n",
    "\n",
    "    if out_file in files:\n",
    "        print (out_file, 'already downloaded')\n",
    "        return\n",
    "    else:\n",
    "        print ('downloading %s from NCBI'%id)\n",
    "        \n",
    "    from Bio import Entrez\n",
    "    Entrez.email = \"vivmol@biosustain.dtu.dk\"     #Insert email here for NCBI\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=id, rettype=\"gb\", retmode=\"text\")\n",
    "    fout = open(out_file,'w')\n",
    "    fout.write(handle.read())\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading CP016552.1 from NCBI\n",
      "downloading CP020030.1 from NCBI\n",
      "downloading CP012712.1 from NCBI\n",
      "downloading CP002835.1 from NCBI\n",
      "downloading CP001638 from NCBI\n",
      "downloading CP008903.1 from NCBI\n"
     ]
    }
   ],
   "source": [
    "# execute the above function, and download the GenBank files for 8 P. thermo strains\n",
    "for strain in targetStrainIDs:\n",
    "    dl_genome(strain, folder='genomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading CP016622.1 from NCBI\n"
     ]
    }
   ],
   "source": [
    "#also download the reference strain info\n",
    "dl_genome(referenceStrainID, folder='genomes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Downloaded Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to gather information of the downloaded strains from the GenBank files\n",
    "def get_strain_info(folder='genomes'):\n",
    "    files = glob('%s/*.gb'%folder)\n",
    "    strain_info = []\n",
    "    \n",
    "    for file in files:\n",
    "        handle = open(file)\n",
    "        record = SeqIO.read(handle, \"genbank\")\n",
    "        \n",
    "        for f in record.features:\n",
    "            if f.type=='source':\n",
    "                info = {}\n",
    "                info['file'] = file\n",
    "                info['id'] = file.split('\\\\')[-1].split('.')[0]\n",
    "                for q in f.qualifiers.keys():\n",
    "                    info[q] = '|'.join(f.qualifiers[q])\n",
    "                strain_info.append(info)\n",
    "    return pd.DataFrame(strain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information on the downloaded strain\n",
    "get_strain_info(folder='genomes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate FASTA files for both Protein and Nucleotide Pipelines\n",
    "From the GenBank file, we can extract sequence and annoation information to generate fasta files for the protein and nucleotide analyses. The resulting fasta files will then be used in step 2 as input for BLAST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to parse the Genbank file to generate fasta files for both protein and nucleotide sequences\n",
    "def parse_genome(id, type='prot', in_folder='genomes', out_folder='prots', overwrite=1):\n",
    "\n",
    "    in_file = '%s/%s.gb'%(in_folder, id)\n",
    "    out_file='%s/%s.fa'%(out_folder, id)\n",
    "    files =glob('%s/*.fa'%out_folder)\n",
    "    \n",
    "    if out_file in files and overwrite==0:\n",
    "        print (out_file, 'already parsed')\n",
    "        return\n",
    "    else:\n",
    "        print ('parsing %s'%id)\n",
    "    \n",
    "    handle = open(in_file)\n",
    "    \n",
    "    fout = open(out_file,'w')\n",
    "    x = 0\n",
    "    \n",
    "    records = SeqIO.parse(handle, \"genbank\")\n",
    "    for record in records:\n",
    "        for f in record.features:\n",
    "            if f.type=='CDS':\n",
    "                seq=f.extract(record.seq)\n",
    "                \n",
    "                if type=='nucl':\n",
    "                    seq=str(seq)\n",
    "                else:\n",
    "                    seq=str(seq.translate())\n",
    "                    \n",
    "                if 'locus_tag' in f.qualifiers.keys():\n",
    "                    locus = f.qualifiers['locus_tag'][0]\n",
    "                elif 'gene' in f.qualifiers.keys():\n",
    "                    locus = f.qualifiers['gene'][0]\n",
    "                else:\n",
    "                    locus = 'gene_%i'%x\n",
    "                    x+=1\n",
    "                fout.write('>%s\\n%s\\n'%(locus, seq))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 2501416905\n",
      "parsing 2501416905\n"
     ]
    }
   ],
   "source": [
    "# Generate fasta files for 5 strains of interest\n",
    "for strain in targetStrainIDs:\n",
    "    parse_genome(strain, type='prot', in_folder='genomes', out_folder='prots')\n",
    "    parse_genome(strain, type='nucl', in_folder='genomes', out_folder='nucl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing NCIMB11955\n",
      "parsing NCIMB11955\n"
     ]
    }
   ],
   "source": [
    "#Also generate fasta files for the reference strain\n",
    "parse_genome(referenceStrainID, type='nucl', in_folder='genomes', out_folder='nucl')\n",
    "parse_genome(referenceStrainID, type='prots', in_folder='genomes', out_folder='prots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform BLAST to find homologous proteins in strains of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make BLAST DB for each of the target strains for both Protein and Nucleotide Pipelines\n",
    "\n",
    "In this tutorial, we will run both BLASTp for proteins and BLSATn for nucleotides. BLASTp will be used as the main approach to identify homologous proteins in reference strain and other strains of interest, while BLASTn will be used as a supplementary method to check for any unannotated genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make blast database for either protein of nucleotide\n",
    "def make_blast_db(id,folder='prots',db_type='prot'):\n",
    "    import os\n",
    "    \n",
    "    out_file ='%s/%s.fa.pin'%(folder, id)\n",
    "    files =glob('%s/*.fa.pin'%folder)\n",
    "    \n",
    "    if out_file in files:\n",
    "        print (id, 'already has a blast db')\n",
    "        return\n",
    "    if db_type=='nucl':\n",
    "        ext='fna'\n",
    "    else:\n",
    "        ext='fa'\n",
    "\n",
    "    cmd_line='makeblastdb -in %s/%s.%s -dbtype %s' %(folder, id, ext, db_type)\n",
    "    \n",
    "    print ('making blast db with following command line...')\n",
    "    print (cmd_line)\n",
    "    os.system(cmd_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\Program Files\\\\NCBI\\\\blast-2.10.1+\\\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making blast db with following command line...\n",
      "makeblastdb -in prots/2501416905.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/NCIMB11955.fa -dbtype prot\n"
     ]
    }
   ],
   "source": [
    "# make protein sequence databases \n",
    "# Because we are performing bi-directional blast, we make databases from both reference strain and strains of interest\n",
    "for strain in targetStrainIDs:\n",
    "    make_blast_db(strain,folder='prots',db_type='prot')\n",
    "make_blast_db(referenceStrainID,folder='prots',db_type='prot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to run protein BLAST and get sequence lengths\n",
    "- BLASTp will be the main approach used here to identify homologous proteins between strains \n",
    "- Aside from sequence similarity, we also want to ensure the coverage of sequence mapping is sufficient. Therefore, we need to identiy the sequence length for each protein and compare it with the alignment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to run BLASTp\n",
    "def run_blastp(seq,db,in_folder='prots', out_folder='bbh', out=None,outfmt=6,evalue=0.001,threads=1):\n",
    "    import os\n",
    "    if out==None:\n",
    "        out='%s/%s_vs_%s.txt'%(out_folder, seq, db)\n",
    "        print(out)\n",
    "    \n",
    "    files =glob('%s/*.txt'%out_folder)\n",
    "    if out in files:\n",
    "        print (seq, 'already blasted')\n",
    "        return\n",
    "    \n",
    "    print ('blasting %s vs %s'%(seq, db))\n",
    "    \n",
    "    db = '%s/%s.fa'%(in_folder, db)\n",
    "    seq = '%s/%s.fa'%(in_folder, seq)\n",
    "    cmd_line='blastp -db %s -query %s -out %s -evalue %s -outfmt %s -num_threads %i' \\\n",
    "    %(db, seq, out, evalue, outfmt, threads)\n",
    "    \n",
    "    print ('running blastp with following command line...')\n",
    "    print (cmd_line)\n",
    "    os.system(cmd_line)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get sequence length \n",
    "\n",
    "def get_gene_lens(query, in_folder='prots'):\n",
    "\n",
    "    file = '%s/%s.fa'%(in_folder, query)\n",
    "    handle = open(file)\n",
    "    records = SeqIO.parse(handle, \"fasta\")\n",
    "    out = []\n",
    "    \n",
    "    for record in records:\n",
    "        out.append({'gene':record.name, 'gene_length':len(record.seq)})\n",
    "    \n",
    "    out = pd.DataFrame(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use Bi-Directional BLASTp Best Hits to create gene presence/absence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Bi-Directional BLASTp Best Hits\n",
    "\n",
    "From the above BLASTp results, we can obtain Bi-Directional BLASTp Best Hits to identify homologous proteins. Note beside gene similarity score, the coverage of alignment is also used to filter mapping results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get Bi-Directional BLASTp Best Hits\n",
    "def get_bbh(query, subject, in_folder='bbh'):    \n",
    "    \n",
    "    #Utilize the defined protein BLAST function\n",
    "    run_blastp(query, subject)\n",
    "    run_blastp(subject, query)\n",
    "    \n",
    "    query_lengths = get_gene_lens(query, in_folder='prots')\n",
    "    subject_lengths = get_gene_lens(subject, in_folder='prots')\n",
    "    \n",
    "    #Define the output file of this BLAST\n",
    "    out_file = '%s/%s_vs_%s_parsed.csv'%(in_folder,query, subject)\n",
    "    files=glob('%s/*_parsed.csv'%in_folder)\n",
    "    \n",
    "    #Combine the results of the protein BLAST into a dataframe\n",
    "    print ('parsing BBHs for', query, subject)\n",
    "    cols = ['gene', 'subject', 'PID', 'alnLength', 'mismatchCount', 'gapOpenCount', 'queryStart', 'queryEnd', 'subjectStart', 'subjectEnd', 'eVal', 'bitScore']\n",
    "    bbh=pd.read_csv('%s/%s_vs_%s.txt'%(in_folder,query, subject), sep='\\t', names=cols)\n",
    "    bbh = pd.merge(bbh, query_lengths) \n",
    "    bbh['COV'] = bbh['alnLength']/bbh['gene_length']\n",
    "    \n",
    "    bbh2=pd.read_csv('%s/%s_vs_%s.txt'%(in_folder,subject, query), sep='\\t', names=cols)\n",
    "    bbh2 = pd.merge(bbh2, subject_lengths) \n",
    "    bbh2['COV'] = bbh2['alnLength']/bbh2['gene_length']\n",
    "    out = pd.DataFrame()\n",
    "    \n",
    "    # Filter the genes based on coverage\n",
    "    bbh = bbh[bbh.COV>=0.25]\n",
    "    bbh2 = bbh2[bbh2.COV>=0.25]\n",
    "    \n",
    "    #Delineate the best hits from the BLAST\n",
    "    for g in bbh.gene.unique():\n",
    "        res = bbh[bbh.gene==g]\n",
    "        if len(res)==0:\n",
    "            continue\n",
    "        best_hit = res.loc[res.PID.idxmax()]\n",
    "        best_gene = best_hit.subject\n",
    "        res2 = bbh2[bbh2.gene==best_gene]\n",
    "        if len(res2)==0:\n",
    "            continue\n",
    "        best_hit2 = res2.loc[res2.PID.idxmax()]\n",
    "        best_gene2 = best_hit2.subject\n",
    "        if g==best_gene2:\n",
    "            best_hit['BBH'] = '<=>'\n",
    "        else:\n",
    "            best_hit['BBH'] = '->'\n",
    "        out=pd.concat([out, pd.DataFrame(best_hit).transpose()])\n",
    "    \n",
    "    #Save the final file to a designated CSV file    \n",
    "    out.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh/NCIMB11955_vs_2501416905.txt\n",
      "blasting NCIMB11955 vs 2501416905\n",
      "running blastp with following command line...\n",
      "blastp -db prots/2501416905.fa -query prots/NCIMB11955.fa -out bbh/NCIMB11955_vs_2501416905.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/2501416905_vs_NCIMB11955.txt\n",
      "blasting 2501416905 vs NCIMB11955\n",
      "running blastp with following command line...\n",
      "blastp -db prots/NCIMB11955.fa -query prots/2501416905.fa -out bbh/2501416905_vs_NCIMB11955.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for NCIMB11955 2501416905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\ipykernel_launcher.py:46 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\pandas\\core\\indexing.py:671 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\ipykernel_launcher.py:44 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Execute the BLAST for each target strain against the reference strain, save results to 'bbh' i.e. \"bidirectional best\n",
    "# hits\" folder to create\n",
    "# homology matrix\n",
    "\n",
    "for strain in targetStrainIDs:\n",
    "    get_bbh(referenceStrainID,strain, in_folder='bbh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the BLAST Results into one Homology Matrix of the Reconstruction Genes\n",
    "\n",
    "For the homology matrix, want to find, for each gene in the reference annotation, is there one in the other strains. And then later filter this down to metabolic genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh\\NCIMB11955_vs_2501416905_parsed.csv (3520, 16)\n"
     ]
    }
   ],
   "source": [
    "#Load all the BLAST files between the reference strain and target strains\n",
    "\n",
    "blast_files=glob('%s/*_parsed.csv'%'bbh')\n",
    "\n",
    "for blast in blast_files:\n",
    "    bbh=pd.read_csv(blast)\n",
    "    print (blast,bbh.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, I will deviate from the published tutorial. In the tutorial, they map the orthologous genes onto the curated model of the reference genome. In reality, we are curious as to how homologous the genomes are to one another, and how many metabolic genes the different strains have in common. So we need to compare the orthologues to the reference genome and not the reference model. I'll try to adapt the scripts so that we can get a homology matrix that captures this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a single dataframe where one column is all the genes in the reference organism, and the other column is a different strain and contains the PID.\n",
    "\n",
    "Then you can count for each column, the number of genes which have a PID above 80% (selected threshold) and compare it to the total number of genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the csv files\n",
    "compare = pd.read_csv('bbh/NCIMB11955_vs_2501416905_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filter out all other columns that i won't use later\n",
    "compare = compare[['gene', 'PID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all ORFs found in the reference genome\n",
    "with open('prots/NCIMB11955.fa') as fasta_file:  # Will close handle cleanly\n",
    "    NCIMB_ids = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "        NCIMB_ids.append(seq_record.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'gene':  NCIMB_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison, compare, on='gene',how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "strains = ['NCIMB11955', 'M10EXG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comparison.columns = strains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe that compares the PID scores for each gene in the reference genome to the other strains, we can start to 'sum up' what percentage of the genes in the reference have a matched gene in the strain. \n",
    "\n",
    "For this, we will set a threshold of 80% sequence identity between genes to be counted as a true homologue. One can decide to change this arbitrarily set value if they like. \n",
    "\n",
    "The reference genome has 3708 ORFs annotated to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M10EXG :  88.9967637540453\n"
     ]
    }
   ],
   "source": [
    "columns = list(comparison) \n",
    "  \n",
    "for i in columns: #iterate through the columns\n",
    "    if i in 'NCIMB11955': # skip reference column\n",
    "        continue\n",
    "    else:\n",
    "        #now go through each row in this column\n",
    "        common_genes = []\n",
    "        for index,row in comparison.iterrows():\n",
    "            value = row[i]\n",
    "            if value > 90: #selected threshold level\n",
    "                common_genes.append(1)\n",
    "            elif value < 90:\n",
    "                common_genes.append(0)\n",
    "    homology = sum(common_genes)\n",
    "    fraction = 100*homology/3708\n",
    "    print(i,': ', fraction)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same as above, but use the E-value as the threshold instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the csv files\n",
    "compare = pd.read_csv('bbh/NCIMB11955_vs_2501416905_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all other columns that i won't use later\n",
    "compare_eval = compare[['gene', 'eVal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframe for first comparison, and then add on the rest\n",
    "comparison_eval = pd.DataFrame({'gene':  NCIMB_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_eval = pd.merge(comparison_eval, compare_eval, on='gene',how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "strains = ['NCIMB11955', 'M10EXG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_eval.columns = strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M10EXG :  94.47141316073355\n"
     ]
    }
   ],
   "source": [
    "columns = list(comparison_eval) \n",
    "  \n",
    "for i in columns: #iterate through the columns\n",
    "    if i in 'NCIMB11955': # skip reference column\n",
    "        continue\n",
    "    else:\n",
    "        #now go through each row in this column\n",
    "        common_genes = []\n",
    "        for index,row in comparison_eval.iterrows():\n",
    "            value = row[i]\n",
    "            if value < 5E-5 : #selected threshold level\n",
    "                common_genes.append(1)\n",
    "            elif value >5E-5:\n",
    "                continue\n",
    "    homology = sum(common_genes)\n",
    "    fraction = (homology/3708)*100\n",
    "    print(i,': ', fraction)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done the above, we can start to look at the overlap between the strains, so that we can create a venn diagram of total ORFs that are unique to each strain but also ovelap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Approach__\n",
    "- Import the fasta files in the prots folder: this is a list of all the ORFs in each strain. \n",
    "\n",
    "- make a list, per strain, of all genes for that strain that fit the comparison threshold (for this use Eval < 1E-10 for now) i.e. all the genes that these two strains have in common\n",
    "\n",
    "- then make an overlap of the all the lists: should give for each strain which are unique and which overlap with one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import total strain lists, for each strain\n",
    "with open('prots/2501416905.fa') as fasta_file:  # Will close handle cleanly\n",
    "    M10EXG_ids = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "        M10EXG_ids.append(seq_record.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to make a dataframe for the comparison of the reference (here NCIMB11955) to the other strain. The list should then contain the gene names of the reference organism, as well as the strain being mapped against. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>eVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gene_0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gene_1</td>\n",
       "      <td>2.600000e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gene_2</td>\n",
       "      <td>2.500000e-104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gene_3</td>\n",
       "      <td>1.620000e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gene_4</td>\n",
       "      <td>7.660000e-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>gene_3752</td>\n",
       "      <td>3.860000e-76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>gene_3753</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>gene_3754</td>\n",
       "      <td>6.070000e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>gene_3755</td>\n",
       "      <td>4.680000e-87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>gene_3756</td>\n",
       "      <td>1.870000e-124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3520 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene           eVal\n",
       "0        gene_0   0.000000e+00\n",
       "1        gene_1   2.600000e-41\n",
       "2        gene_2  2.500000e-104\n",
       "3        gene_3   1.620000e-54\n",
       "4        gene_4  7.660000e-127\n",
       "...         ...            ...\n",
       "3515  gene_3752   3.860000e-76\n",
       "3516  gene_3753   0.000000e+00\n",
       "3517  gene_3754   6.070000e-51\n",
       "3518  gene_3755   4.680000e-87\n",
       "3519  gene_3756  1.870000e-124\n",
       "\n",
       "[3520 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_reference = [] #the overlapping genes, with the reference strain ID\n",
    "ol_strain =[] #the overlapping genes, with the reference strain ID\n",
    "for index,row in compare.iterrows():\n",
    "    value = row['eVal']\n",
    "    if value > 1E-5: #selected threshold level\n",
    "        continue #we don't want to save these anywhere            \n",
    "    elif value < 1E-5:\n",
    "        ol_reference.append(row['gene'])\n",
    "        ol_strain.append(row['subject'])\n",
    "NCIMB_M10EXG_OL =  pd.DataFrame({'NCIMB11955': ol_reference, 'M10EXG': ol_strain})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so NCIMB_M10EXG_OL is now a dataframe that maps each gene in the NCIMB to a gene in M10EXG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NCIMB_M10EXG_OL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, you then see which 3498 genes of the target strain match the reference strain.\n",
    "We can then see how many genes each strain has by themselves and from that make the venndiagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NCIMB_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So NCIMB has 259 unique ORFs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we had NCIMB as the reference strain. TO find how many true unique genes there are in M10EXG, we would need to repeat the above analysis but now with M10EXG as reference strain. That will be done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>NCBI ID</th>\n",
       "      <th>Physiology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goebacillus thermoglucosidasius NCIMB11955</td>\n",
       "      <td>NCIMB11955</td>\n",
       "      <td>Facultative anaerobe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Strain     NCBI ID  \\\n",
       "0  Goebacillus thermoglucosidasius NCIMB11955  NCIMB11955   \n",
       "\n",
       "             Physiology  \n",
       "0  Facultative anaerobe  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrainsOfInterest=pd.read_excel('Strain InformationB.xlsx')\n",
    "StrainsOfInterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch reference and target here\n",
    "referenceStrainID='2501416905'\n",
    "targetStrainIDs=list(StrainsOfInterest['NCBI ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh/2501416905_vs_NCIMB11955.txt\n",
      "blasting 2501416905 vs NCIMB11955\n",
      "running blastp with following command line...\n",
      "blastp -db prots/NCIMB11955.fa -query prots/2501416905.fa -out bbh/2501416905_vs_NCIMB11955.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/NCIMB11955_vs_2501416905.txt\n",
      "blasting NCIMB11955 vs 2501416905\n",
      "running blastp with following command line...\n",
      "blastp -db prots/2501416905.fa -query prots/NCIMB11955.fa -out bbh/NCIMB11955_vs_2501416905.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for 2501416905 NCIMB11955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\ipykernel_launcher.py:44 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\pandas\\core\\indexing.py:671 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo-copy\\lib\\site-packages\\ipykernel_launcher.py:46 SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "for strain in targetStrainIDs:\n",
    "    get_bbh(referenceStrainID,strain, in_folder='bbh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import this file and make it into a dataframe so we can find the unique genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the csv files\n",
    "compare = pd.read_csv('bbh/2501416905_vs_NCIMB11955_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all other columns that i won't use later\n",
    "compare_eval = compare[['gene', 'eVal', 'subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "strains = ['M10EXG', 'eVal', 'NCIMB11955']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_eval.columns = strains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done the above, we can slook at the overlap from M10EXg to the NCIMB strain. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Approach__\n",
    "- make a list, per strain, of all genes for that strain that fit the comparison threshold (for this use Eval < 1E-5 for now) i.e. all the genes that these two strains have in common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_reference = [] #the overlapping genes, with the reference strain ID\n",
    "ol_strain =[] #the overlapping genes, with the reference strain ID\n",
    "for index,row in compare_eval.iterrows():\n",
    "    value = row['eVal']\n",
    "    if value > 1E-5: #selected threshold level\n",
    "        continue #we don't want to save these anywhere            \n",
    "    elif value < 1E-5:\n",
    "        ol_reference.append(row['M10EXG'])\n",
    "        ol_strain.append(row['NCIMB11955'])\n",
    "M10EXG_NCIMB_OL =  pd.DataFrame({'M10EXG': ol_reference, 'NCIMB': ol_strain})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so M10EXG_NCIMB_OL is now a dataframe that maps each gene in the M10EXG to a gene in NCIMB11955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3493"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M10EXG_NCIMB_OL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 genes less mapped as overlap, but this is within the error range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3727"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M10EXG_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we would have 234 unique genes in M10EXG. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So overall, we have 3498 genes that overlap, 259 unique in NCIMB and 234 unique in M10EXG. This very closely matches the results of the KBASE pipeline we did, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for metabolic genes\n",
    "Now that we know the overlap in the total protein, we want to find out what percentage of the metabolic genes overlap between the strains. So first I will filter all the genes from the target organism into the ones that are metabolic genes. And then apply this list to the list of bi-directional hits, so see how many of the metabolic genes overlap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't get the definition to work, So I will just write a script that will make a dataframe linking each gene to a possible EC code. Then we can filter the bbh-file made previously for these metabolic genes and get the answer that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genes = []\n",
    "EC = []\n",
    "x = 0\n",
    "for seq_record in SeqIO.parse(\"genomes/NCIMB11955.gb\", \"genbank\"):\n",
    "     for f in seq_record.features:\n",
    "        if f.type=='CDS':\n",
    "            if 'locus_tag' in f.qualifiers.keys():\n",
    "                locus = f.qualifiers['locus_tag'][0]\n",
    "            elif 'gene' in f.qualifiers.keys():\n",
    "                locus = f.qualifiers['gene'][0]\n",
    "            else:\n",
    "                locus = 'gene_%i'%x\n",
    "                x+=1\n",
    "            try:\n",
    "                synonyms = f.qualifiers['gene_synonym']\n",
    "                #here it will check that it has one of the gene_synonyms as ec code, i.e. is metabolic\n",
    "                check = []\n",
    "                for a in synonyms:\n",
    "                    if a[0].isdigit():\n",
    "                        ec = a\n",
    "                        check.append(1)\n",
    "                    else:\n",
    "                        continue\n",
    "                if sum(check) > 0:\n",
    "                    \n",
    "                    genes.append(locus)\n",
    "                    EC.append(a)\n",
    "            except KeyError:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCIMB_met = pd.DataFrame({'Gene': genes, 'EC': EC})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll do the same for the M10EXG genome/annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = []\n",
    "EC = []\n",
    "x = 0\n",
    "for seq_record in SeqIO.parse(\"genomes/2501416905.gb\", \"genbank\"):\n",
    "     for f in seq_record.features:\n",
    "        if f.type=='CDS':\n",
    "            if 'locus_tag' in f.qualifiers.keys():\n",
    "                locus = f.qualifiers['locus_tag'][0]\n",
    "            elif 'gene' in f.qualifiers.keys():\n",
    "                locus = f.qualifiers['gene'][0]\n",
    "            else:\n",
    "                locus = 'gene_%i'%x\n",
    "                x+=1\n",
    "            try:\n",
    "                synonyms = f.qualifiers['gene_synonym']\n",
    "                #here it will check that it has one of the gene_synonyms as ec code, i.e. is metabolic\n",
    "                check = []\n",
    "                for a in synonyms:\n",
    "                    if a[0].isdigit():\n",
    "                        ec = a\n",
    "                        check.append(1)\n",
    "                    else:\n",
    "                        continue\n",
    "                if sum(check) > 0:\n",
    "                    \n",
    "                    genes.append(locus)\n",
    "                    EC.append(a)\n",
    "            except KeyError:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10EXG_met = pd.DataFrame({'Gene': genes, 'EC': EC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1424"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NCIMB_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1417"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M10EXG_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this shows we have 1424 metabolic genes in the reference strain and 1417 in the M10EXG strain. Note, there are ofcourse many hypothetical proteins annotated in the genome. Those are ignored. \n",
    "Now, I will have to filter the list of BBH based on just the genes that are metabolic. \n",
    "\n",
    "Approach:\n",
    "- NCIMB_M10EXG_OL has all the CDS that are considered hits here (with the threshold of 1E-5 set). I will iterate through each row, and make a new dataframe which contains the filtered set of genes for comparing.\n",
    "\n",
    "NOTE: at the end of comparing with NCIMC11955 as reference, I will do the same with the M10EXG as reference, to find which genes are unique there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCIMB = []\n",
    "M10EXG = []\n",
    "for row, index in NCIMB_M10EXG_OL.iterrows():\n",
    "    ref_gene = index['NCIMB11955']\n",
    "    try:\n",
    "        NCIMB_met.loc[NCIMB_met[\"Gene\"] == ref_gene,'EC'].values[0] #if it is a metaoblic gene this will give a hit\n",
    "        NCIMB.append(index['NCIMB11955'])\n",
    "        M10EXG.append(index['M10EXG'])\n",
    "    except IndexError: #if the hit isn't metabolic, we can ignore it\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data frame\n",
    "OL_metabolic = pd.DataFrame({'NCIMB11955':NCIMB, 'M10EXG':M10EXG})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(OL_metabolic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 1384 metabolic genes that overlap. That means there are 40 genes unique to NCIMB, and for M10EXG we need to check how many are still unmatched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will make a list of the unique metabolic genes, that can be supplied in supplementary, and given a short look through if anything unexpected appears.\n",
    "\n",
    "Approach:\n",
    "- NCIMB_met and M10EXG_met has all the metabolic genes with their corresponding EC code. I will filter out the significant hits here for the NCIMB strain first. I need to repeat the above analysis for M10EXG to be able to see how many unique it has properly. (will be done further in this notebook)\n",
    "- then try to find some more information about each E.C. code, e.g. from KEGG database I've Used before? I can look into the type of reactions (i.e. category) and/or the extact reaction name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = []\n",
    "ECs =[]\n",
    "for row, index in NCIMB_met.iterrows():\n",
    "    gene = index['Gene']\n",
    "    try:\n",
    "        OL_metabolic.loc[OL_metabolic[\"NCIMB11955\"] == gene,'M10EXG'].values[0] #If the gene is in the overlap dataframe it will give an output\n",
    "        continue\n",
    "    except IndexError: #i.e. if the gene doesn't have an overlap in M10EXG\n",
    "        genes.append(gene)\n",
    "        ECs.append(index['EC'])\n",
    "        \n",
    "#make dataframe\n",
    "NCIMB_unique = pd.DataFrame({'Unique gene':genes, 'EC':ECs}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NCIMB_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that for NCIMB, there are 40 unique metabolic genes and 1384 overlapping genes. I will do the same as above but for the M10EXG strain to find how many are unique in that strain when that is used as reference sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10EXG = []\n",
    "NCIMB = []\n",
    "for row, index in M10EXG_NCIMB_OL.iterrows():\n",
    "    ref_gene = index['M10EXG']\n",
    "    try:\n",
    "        M10EXG_met.loc[M10EXG_met[\"Gene\"] == ref_gene,'EC'].values[0] #if it is a metaoblic gene this will give a hit\n",
    "        M10EXG.append(index['M10EXG'])\n",
    "        NCIMB.append(index['NCIMB'])\n",
    "    except IndexError: #if the hit isn't metabolic, we can ignore it\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data frame\n",
    "OL_metabolic_M10EXG = pd.DataFrame({'M10EXG':M10EXG, 'NCIMB11955':NCIMB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(OL_metabolic_M10EXG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again here there is a difference of a few genes, but falls within an error range if you consider the size of the total metabolic gene set. So this is fine. Next, we will make a dataframe of the metabolic genes that are unique to M10EXG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = []\n",
    "ECs =[]\n",
    "for row, index in M10EXG_met.iterrows():\n",
    "    gene = index['Gene']\n",
    "    try:\n",
    "        OL_metabolic_M10EXG.loc[OL_metabolic_M10EXG[\"M10EXG\"] == gene,'NCIMB11955'].values[0] #If the gene is in the overlap dataframe it will give an output\n",
    "        continue\n",
    "    except IndexError: #i.e. if the gene doesn't have an overlap in M10EXG\n",
    "        genes.append(gene)\n",
    "        ECs.append(index['EC'])\n",
    "        \n",
    "#make dataframe\n",
    "M10EXG_unique = pd.DataFrame({'Unique gene':genes, 'EC':ECs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M10EXG_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 29 unique genes in M10EXG, and 40 in our strain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two dataframes, one for each strain, with the unique metabolic genes, we can try to find a bit more information about them. I will try to get a name for the reaction, as well as what pathway they are a part of. \n",
    "\n",
    "First I will prepare a dataframe from the KEGG Site that contains the information about which pathway the EC code belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://rest.kegg.jp/link/ec/pathway', header=None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Pathway', 'EC'] #rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all 'path:' and 'rn:'\n",
    "df['Pathway'] = df['Pathway'].str.replace(r'path:ec', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EC'] = df['EC'].str.replace(r'ec:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the rows with 'path_map' to prevent duplication\n",
    "df = df[~df['Pathway'].str.contains(\"map\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now link the pathway code to the name of the pathway it is involved in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_groups = pd.read_csv('http://rest.kegg.jp/list/pathway', header=None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.columns = ['Pathway', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups['Pathway'] = df_groups['Pathway'].str.replace(r'path:map', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now filter out the IDs I dont want to include\n",
    "#i want to remove all rows below number 153\n",
    "df_groups = df_groups[0:154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then merge the df and df_groups together\n",
    "df = pd.merge(df_groups,df,on='Pathway',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can map the EC code from the unique metabolic reaction lists to these pathway classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway =[]\n",
    "for index, row in NCIMB_unique.iterrows():\n",
    "    ec = row['EC']\n",
    "    types =[]\n",
    "    found = df.loc[df[\"EC\"] == ec]\n",
    "    for indexa, rowa in found.iterrows() :\n",
    "        types.append(rowa['Name']) \n",
    "    pathway.append(types)\n",
    "NCIMB_unique['Pathway'] = pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway =[]\n",
    "for index, row in M10EXG_unique.iterrows():\n",
    "    ec = row['EC']\n",
    "    types =[]\n",
    "    found = df.loc[df[\"EC\"] == ec]\n",
    "    for indexa, rowa in found.iterrows() :\n",
    "        types.append(rowa['Name']) \n",
    "    pathway.append(types)\n",
    "M10EXG_unique['Pathway'] = pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll also add a column which looks at the KO of the ec codes recognized so that we get a bit more information about which reactions are unique in each strain.\n",
    "\n",
    "First I will prepare a dataframe that contains the EC codes linked to the KO ontology terms for these annotations. That we can use to map the unique reactions to.\n",
    "There will probably still be some that are not mapped, those we will need to check by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://rest.kegg.jp/link/ec/ko', header=None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['KO', 'EC'] #rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all 'ko:' and 'ec:'\n",
    "df['KO'] = df['KO'].str.replace(r'ko:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EC'] = df['EC'].str.replace(r'ec:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now import the list of KO terms with more meaningful description\n",
    "ko = pd.read_csv('http://rest.kegg.jp/list/ko', header=None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko.columns = ['KO', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko['KO'] = ko['KO'].str.replace(r'ko:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link the two dataframes together\n",
    "df = pd.merge(df,ko,on='KO',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can map the EC code to a KO term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_term =[]\n",
    "for index, row in NCIMB_unique.iterrows():\n",
    "    ec = row['EC']\n",
    "    types =[]\n",
    "    found = df.loc[df[\"EC\"] == ec]\n",
    "    for indexa, rowa in found.iterrows() :\n",
    "        types.append(rowa['Name']) \n",
    "    ko_term.append(types)\n",
    "NCIMB_unique['KO'] = ko_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_term =[]\n",
    "for index, row in M10EXG_unique.iterrows():\n",
    "    ec = row['EC']\n",
    "    types =[]\n",
    "    found = df.loc[df[\"EC\"] == ec]\n",
    "    for indexa, rowa in found.iterrows() :\n",
    "        types.append(rowa['Name']) \n",
    "    ko_term.append(types)\n",
    "M10EXG_unique['KO'] = ko_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will export these two tables and need to some some manual inspection of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10EXG_unique.to_csv('M10EXG_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCIMB_unique.to_csv('NCIMB_unique.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
