{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Homology matrix generation from genome sequences\n",
    "\n",
    "In this notebook, I will be applying the notebooks accompanying the paper by Norsigian et al., 2020. (doi:10.1038/s41596-019-0254-3.) I will apply this for the P. thermo model we've been working on and some related strains:\n",
    "- G. thermoglucosidaius DSM2542\n",
    "- G. thermoglucosidasius C56-YS93\n",
    "- Geobacillus thermoglucosidans TNO-09.020\n",
    "- Geobacillus sp. Y4.1MC1\n",
    "- Geobacillus sp. WCH70\n",
    "- Geobacillus LC300\n",
    "- Geobacillus stearothermophilus DSM 458\n",
    "- Geobacillus thermodenitrificans T12\n",
    "\n",
    "\n",
    "This is the the first notebook in the tutorial to create homology matrix from genome sequences.There are four major steps in this notebook\n",
    "1. Download the genome annotation (GenBank files) from NCBI, and generate fasta files (protein &nucleotide) from them\n",
    "2. Perform BLASTp to find homologous proteins in strains of interest\n",
    "3. Use best bidirectional hits to create gene presence/absence matrix\n",
    "4. Supplementary for best practice: use BLASTn to check if we have missed any unannotated open reading frames and retain these genes in orthology matrix as well as guide future manual curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__ to be able to import the Entrez and SeqIO, I need to change the folder name from 'bio' to 'Bio' and then it'll work. \n",
    "\n",
    "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo\\Lib\\site-packages\n",
    "\n",
    "So be careful whenever i install Biopython again that this needs to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be working with strains in the faculative anaerobic clade of the genus. I will also add genomes that are obligate aerobes to see if that could highlight to us what changed between these species that made them become obligate aerobes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>NCBI ID</th>\n",
       "      <th>Oxygen requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geobacillus stearothermophilus DSM 458</td>\n",
       "      <td>CP016552.1</td>\n",
       "      <td>Obligate aerobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geobacillus thermodenitrificans T12</td>\n",
       "      <td>CP020030.1</td>\n",
       "      <td>Obligate aerobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G. thermoglucosidaius DSM2542</td>\n",
       "      <td>CP012712.1</td>\n",
       "      <td>Facultative anaerobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G. thermoglucosidasius C56-YS93</td>\n",
       "      <td>CP002835.1</td>\n",
       "      <td>Facultative anaerobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geobacillus sp. WCH70</td>\n",
       "      <td>CP001638</td>\n",
       "      <td>Facultative anaerobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Geobacillus LC300</td>\n",
       "      <td>CP008903.1</td>\n",
       "      <td>Obligate aerobe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Strain     NCBI ID    Oxygen requirement\n",
       "0  Geobacillus stearothermophilus DSM 458  CP016552.1       Obligate aerobe\n",
       "1     Geobacillus thermodenitrificans T12  CP020030.1       Obligate aerobe\n",
       "2           G. thermoglucosidaius DSM2542  CP012712.1  Facultative anaerobe\n",
       "3         G. thermoglucosidasius C56-YS93  CP002835.1  Facultative anaerobe\n",
       "4                   Geobacillus sp. WCH70    CP001638  Facultative anaerobe\n",
       "5                       Geobacillus LC300  CP008903.1       Obligate aerobe"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the information on the five strains we will be working with in this tutorial\n",
    "StrainsOfInterest=pd.read_excel('Strain Information.xlsx')\n",
    "StrainsOfInterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Reference Genome is as Described in the Base Reconstruction; here the reference is \n",
    "referenceStrainID='CP016622.1'\n",
    "targetStrainIDs=list(StrainsOfInterest['NCBI ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download genome annotations (GenBank files) to generate fasta files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload genomes from NCBI\n",
    "Download the genome annotations (GenBank files) from NCBI for strains of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to download the annotated genebank files from NCBI\n",
    "def dl_genome(id, folder='genomes'): # be sure get CORRECT ID\n",
    "    files=glob('%s/*.gb'%folder)\n",
    "    out_file = '%s/%s.gb'%(folder, id)\n",
    "\n",
    "    if out_file in files:\n",
    "        print (out_file, 'already downloaded')\n",
    "        return\n",
    "    else:\n",
    "        print ('downloading %s from NCBI'%id)\n",
    "        \n",
    "    from Bio import Entrez\n",
    "    Entrez.email = \"vivmol@biosustain.dtu.dk\"     #Insert email here for NCBI\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=id, rettype=\"gb\", retmode=\"text\")\n",
    "    fout = open(out_file,'w')\n",
    "    fout.write(handle.read())\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading CP016552.1 from NCBI\n",
      "downloading CP020030.1 from NCBI\n",
      "downloading CP012712.1 from NCBI\n",
      "downloading CP002835.1 from NCBI\n",
      "downloading CP001638 from NCBI\n",
      "downloading CP008903.1 from NCBI\n"
     ]
    }
   ],
   "source": [
    "# execute the above function, and download the GenBank files for 8 P. thermo strains\n",
    "for strain in targetStrainIDs:\n",
    "    dl_genome(strain, folder='genomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading CP016622.1 from NCBI\n"
     ]
    }
   ],
   "source": [
    "#also download the reference strain info\n",
    "dl_genome(referenceStrainID, folder='genomes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Downloaded Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to gather information of the downloaded strains from the GenBank files\n",
    "def get_strain_info(folder='genomes'):\n",
    "    files = glob('%s/*.gb'%folder)\n",
    "    strain_info = []\n",
    "    \n",
    "    for file in files:\n",
    "        handle = open(file)\n",
    "        record = SeqIO.read(handle, \"genbank\")\n",
    "        \n",
    "        for f in record.features:\n",
    "            if f.type=='source':\n",
    "                info = {}\n",
    "                info['file'] = file\n",
    "                info['id'] = file.split('\\\\')[-1].split('.')[0]\n",
    "                for q in f.qualifiers.keys():\n",
    "                    info[q] = '|'.join(f.qualifiers[q])\n",
    "                strain_info.append(info)\n",
    "    return pd.DataFrame(strain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>organism</th>\n",
       "      <th>mol_type</th>\n",
       "      <th>strain</th>\n",
       "      <th>db_xref</th>\n",
       "      <th>isolation_source</th>\n",
       "      <th>culture_collection</th>\n",
       "      <th>type_material</th>\n",
       "      <th>country</th>\n",
       "      <th>collection_date</th>\n",
       "      <th>lat_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genomes\\CP001638.gb</td>\n",
       "      <td>CP001638</td>\n",
       "      <td>Geobacillus sp. WCH70</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>WCH70</td>\n",
       "      <td>taxon:471223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genomes\\CP002835.1.gb</td>\n",
       "      <td>CP002835</td>\n",
       "      <td>Parageobacillus thermoglucosidasius C56-YS93</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>C56-YS93</td>\n",
       "      <td>taxon:634956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genomes\\CP008903.1.gb</td>\n",
       "      <td>CP008903</td>\n",
       "      <td>Geobacillus sp. LC300</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>LC300</td>\n",
       "      <td>taxon:1519377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genomes\\CP012712.1.gb</td>\n",
       "      <td>CP012712</td>\n",
       "      <td>Parageobacillus thermoglucosidasius</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>DSM 2542</td>\n",
       "      <td>taxon:1426</td>\n",
       "      <td>soil</td>\n",
       "      <td>DSM:2542</td>\n",
       "      <td>type strain of Parageobacillus thermoglucosida...</td>\n",
       "      <td>China: Beijing</td>\n",
       "      <td>01-Jan-2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genomes\\CP016552.1.gb</td>\n",
       "      <td>CP016552</td>\n",
       "      <td>Geobacillus stearothermophilus</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>DSM 458</td>\n",
       "      <td>taxon:1422</td>\n",
       "      <td>sugar beet juice from extraction installations</td>\n",
       "      <td>DSM:458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>genomes\\CP016622.1.gb</td>\n",
       "      <td>CP016622</td>\n",
       "      <td>Parageobacillus thermoglucosidasius</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>NCIMB 11955</td>\n",
       "      <td>taxon:1426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIMB:11955</td>\n",
       "      <td>type strain of Parageobacillus thermoglucosida...</td>\n",
       "      <td>United Kingdom: Surrey</td>\n",
       "      <td>01-Jun-2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>genomes\\CP020030.1.gb</td>\n",
       "      <td>CP020030</td>\n",
       "      <td>Geobacillus thermodenitrificans</td>\n",
       "      <td>genomic DNA</td>\n",
       "      <td>T12</td>\n",
       "      <td>taxon:33940</td>\n",
       "      <td>soil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Netherlands:ede</td>\n",
       "      <td>22-Oct-2012</td>\n",
       "      <td>52.0439 N 5.6167 E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file        id  \\\n",
       "0    genomes\\CP001638.gb  CP001638   \n",
       "1  genomes\\CP002835.1.gb  CP002835   \n",
       "2  genomes\\CP008903.1.gb  CP008903   \n",
       "3  genomes\\CP012712.1.gb  CP012712   \n",
       "4  genomes\\CP016552.1.gb  CP016552   \n",
       "5  genomes\\CP016622.1.gb  CP016622   \n",
       "6  genomes\\CP020030.1.gb  CP020030   \n",
       "\n",
       "                                       organism     mol_type       strain  \\\n",
       "0                         Geobacillus sp. WCH70  genomic DNA        WCH70   \n",
       "1  Parageobacillus thermoglucosidasius C56-YS93  genomic DNA     C56-YS93   \n",
       "2                         Geobacillus sp. LC300  genomic DNA        LC300   \n",
       "3           Parageobacillus thermoglucosidasius  genomic DNA     DSM 2542   \n",
       "4                Geobacillus stearothermophilus  genomic DNA      DSM 458   \n",
       "5           Parageobacillus thermoglucosidasius  genomic DNA  NCIMB 11955   \n",
       "6               Geobacillus thermodenitrificans  genomic DNA          T12   \n",
       "\n",
       "         db_xref                                isolation_source  \\\n",
       "0   taxon:471223                                             NaN   \n",
       "1   taxon:634956                                             NaN   \n",
       "2  taxon:1519377                                             NaN   \n",
       "3     taxon:1426                                            soil   \n",
       "4     taxon:1422  sugar beet juice from extraction installations   \n",
       "5     taxon:1426                                             NaN   \n",
       "6    taxon:33940                                            soil   \n",
       "\n",
       "  culture_collection                                      type_material  \\\n",
       "0                NaN                                                NaN   \n",
       "1                NaN                                                NaN   \n",
       "2                NaN                                                NaN   \n",
       "3           DSM:2542  type strain of Parageobacillus thermoglucosida...   \n",
       "4            DSM:458                                                NaN   \n",
       "5        NCIMB:11955  type strain of Parageobacillus thermoglucosida...   \n",
       "6                NaN                                                NaN   \n",
       "\n",
       "                  country collection_date             lat_lon  \n",
       "0                     NaN             NaN                 NaN  \n",
       "1                     NaN             NaN                 NaN  \n",
       "2                     NaN             NaN                 NaN  \n",
       "3          China: Beijing     01-Jan-2010                 NaN  \n",
       "4                 Austria             NaN                 NaN  \n",
       "5  United Kingdom: Surrey     01-Jun-2014                 NaN  \n",
       "6         Netherlands:ede     22-Oct-2012  52.0439 N 5.6167 E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information on the downloaded strain\n",
    "get_strain_info(folder='genomes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate FASTA files for both Protein and Nucleotide Pipelines\n",
    "From the GenBank file, we can extract sequence and annoation information to generate fasta files for the protein and nucleotide analyses. The resulting fasta files will then be used in step 2 as input for BLAST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to parse the Genbank file to generate fasta files for both protein and nucleotide sequences\n",
    "def parse_genome(id, type='prot', in_folder='genomes', out_folder='prots', overwrite=1):\n",
    "\n",
    "    in_file = '%s/%s.gb'%(in_folder, id)\n",
    "    out_file='%s/%s.fa'%(out_folder, id)\n",
    "    files =glob('%s/*.fa'%out_folder)\n",
    "    \n",
    "    if out_file in files and overwrite==0:\n",
    "        print (out_file, 'already parsed')\n",
    "        return\n",
    "    else:\n",
    "        print ('parsing %s'%id)\n",
    "    \n",
    "    handle = open(in_file)\n",
    "    \n",
    "    fout = open(out_file,'w')\n",
    "    x = 0\n",
    "    \n",
    "    records = SeqIO.parse(handle, \"genbank\")\n",
    "    for record in records:\n",
    "        for f in record.features:\n",
    "            if f.type=='CDS':\n",
    "                seq=f.extract(record.seq)\n",
    "                \n",
    "                if type=='nucl':\n",
    "                    seq=str(seq)\n",
    "                else:\n",
    "                    seq=str(seq.translate())\n",
    "                    \n",
    "                if 'locus_tag' in f.qualifiers.keys():\n",
    "                    locus = f.qualifiers['locus_tag'][0]\n",
    "                elif 'gene' in f.qualifiers.keys():\n",
    "                    locus = f.qualifiers['gene'][0]\n",
    "                else:\n",
    "                    locus = 'gene_%i'%x\n",
    "                    x+=1\n",
    "                fout.write('>%s\\n%s\\n'%(locus, seq))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing CP016552.1\n",
      "parsing CP016552.1\n",
      "parsing CP020030.1\n",
      "parsing CP020030.1\n",
      "parsing CP012712.1\n",
      "parsing CP012712.1\n",
      "parsing CP002835.1\n",
      "parsing CP002835.1\n",
      "parsing CP001638\n",
      "parsing CP001638\n",
      "parsing CP008903.1\n",
      "parsing CP008903.1\n"
     ]
    }
   ],
   "source": [
    "# Generate fasta files for 5 strains of interest\n",
    "for strain in targetStrainIDs:\n",
    "    parse_genome(strain, type='prot', in_folder='genomes', out_folder='prots')\n",
    "    parse_genome(strain, type='nucl', in_folder='genomes', out_folder='nucl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing CP016622.1\n",
      "parsing CP016622.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivmol\\AppData\\Local\\Continuum\\anaconda3\\envs\\g-thermo\\lib\\site-packages\\Bio\\Seq.py:2334: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Also generate fasta files for the reference strain\n",
    "parse_genome(referenceStrainID, type='nucl', in_folder='genomes', out_folder='nucl')\n",
    "parse_genome(referenceStrainID, type='prots', in_folder='genomes', out_folder='prots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform BLAST to find homologous proteins in strains of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make BLAST DB for each of the target strains for both Protein and Nucleotide Pipelines\n",
    "\n",
    "In this tutorial, we will run both BLASTp for proteins and BLSATn for nucleotides. BLASTp will be used as the main approach to identify homologous proteins in reference strain and other strains of interest, while BLASTn will be used as a supplementary method to check for any unannotated genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make blast database for either protein of nucleotide\n",
    "def make_blast_db(id,folder='prots',db_type='prot'):\n",
    "    import os\n",
    "    \n",
    "    out_file ='%s/%s.fa.pin'%(folder, id)\n",
    "    files =glob('%s/*.fa.pin'%folder)\n",
    "    \n",
    "    if out_file in files:\n",
    "        print (id, 'already has a blast db')\n",
    "        return\n",
    "    if db_type=='nucl':\n",
    "        ext='fna'\n",
    "    else:\n",
    "        ext='fa'\n",
    "\n",
    "    cmd_line='makeblastdb -in %s/%s.%s -dbtype %s' %(folder, id, ext, db_type)\n",
    "    \n",
    "    print ('making blast db with following command line...')\n",
    "    print (cmd_line)\n",
    "    os.system(cmd_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\Program Files\\\\NCBI\\\\blast-2.10.1+\\\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP016552.1.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP020030.1.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP012712.1.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP002835.1.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP001638.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP008903.1.fa -dbtype prot\n",
      "making blast db with following command line...\n",
      "makeblastdb -in prots/CP016622.1.fa -dbtype prot\n"
     ]
    }
   ],
   "source": [
    "# make protein sequence databases \n",
    "# Because we are performing bi-directional blast, we make databases from both reference strain and strains of interest\n",
    "for strain in targetStrainIDs:\n",
    "    make_blast_db(strain,folder='prots',db_type='prot')\n",
    "make_blast_db(referenceStrainID,folder='prots',db_type='prot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to run protein BLAST and get sequence lengths\n",
    "- BLASTp will be the main approach used here to identify homologous proteins between strains \n",
    "- Aside from sequence similarity, we also want to ensure the coverage of sequence mapping is sufficient. Therefore, we need to identiy the sequence length for each protein and compare it with the alignment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to run BLASTp\n",
    "def run_blastp(seq,db,in_folder='prots', out_folder='bbh', out=None,outfmt=6,evalue=0.001,threads=1):\n",
    "    import os\n",
    "    if out==None:\n",
    "        out='%s/%s_vs_%s.txt'%(out_folder, seq, db)\n",
    "        print(out)\n",
    "    \n",
    "    files =glob('%s/*.txt'%out_folder)\n",
    "    if out in files:\n",
    "        print (seq, 'already blasted')\n",
    "        return\n",
    "    \n",
    "    print ('blasting %s vs %s'%(seq, db))\n",
    "    \n",
    "    db = '%s/%s.fa'%(in_folder, db)\n",
    "    seq = '%s/%s.fa'%(in_folder, seq)\n",
    "    cmd_line='blastp -db %s -query %s -out %s -evalue %s -outfmt %s -num_threads %i' \\\n",
    "    %(db, seq, out, evalue, outfmt, threads)\n",
    "    \n",
    "    print ('running blastp with following command line...')\n",
    "    print (cmd_line)\n",
    "    os.system(cmd_line)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get sequence length \n",
    "\n",
    "def get_gene_lens(query, in_folder='prots'):\n",
    "\n",
    "    file = '%s/%s.fa'%(in_folder, query)\n",
    "    handle = open(file)\n",
    "    records = SeqIO.parse(handle, \"fasta\")\n",
    "    out = []\n",
    "    \n",
    "    for record in records:\n",
    "        out.append({'gene':record.name, 'gene_length':len(record.seq)})\n",
    "    \n",
    "    out = pd.DataFrame(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use Bi-Directional BLASTp Best Hits to create gene presence/absence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Bi-Directional BLASTp Best Hits\n",
    "\n",
    "From the above BLASTp results, we can obtain Bi-Directional BLASTp Best Hits to identify homologous proteins. Note beside gene similarity score, the coverage of alignment is also used to filter mapping results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get Bi-Directional BLASTp Best Hits\n",
    "def get_bbh(query, subject, in_folder='bbh'):    \n",
    "    \n",
    "    #Utilize the defined protein BLAST function\n",
    "    run_blastp(query, subject)\n",
    "    run_blastp(subject, query)\n",
    "    \n",
    "    query_lengths = get_gene_lens(query, in_folder='prots')\n",
    "    subject_lengths = get_gene_lens(subject, in_folder='prots')\n",
    "    \n",
    "    #Define the output file of this BLAST\n",
    "    out_file = '%s/%s_vs_%s_parsed.csv'%(in_folder,query, subject)\n",
    "    files=glob('%s/*_parsed.csv'%in_folder)\n",
    "    \n",
    "    #Combine the results of the protein BLAST into a dataframe\n",
    "    print ('parsing BBHs for', query, subject)\n",
    "    cols = ['gene', 'subject', 'PID', 'alnLength', 'mismatchCount', 'gapOpenCount', 'queryStart', 'queryEnd', 'subjectStart', 'subjectEnd', 'eVal', 'bitScore']\n",
    "    bbh=pd.read_csv('%s/%s_vs_%s.txt'%(in_folder,query, subject), sep='\\t', names=cols)\n",
    "    bbh = pd.merge(bbh, query_lengths) \n",
    "    bbh['COV'] = bbh['alnLength']/bbh['gene_length']\n",
    "    \n",
    "    bbh2=pd.read_csv('%s/%s_vs_%s.txt'%(in_folder,subject, query), sep='\\t', names=cols)\n",
    "    bbh2 = pd.merge(bbh2, subject_lengths) \n",
    "    bbh2['COV'] = bbh2['alnLength']/bbh2['gene_length']\n",
    "    out = pd.DataFrame()\n",
    "    \n",
    "    # Filter the genes based on coverage\n",
    "    bbh = bbh[bbh.COV>=0.25]\n",
    "    bbh2 = bbh2[bbh2.COV>=0.25]\n",
    "    \n",
    "    #Delineate the best hits from the BLAST\n",
    "    for g in bbh.gene.unique():\n",
    "        res = bbh[bbh.gene==g]\n",
    "        if len(res)==0:\n",
    "            continue\n",
    "        best_hit = res.loc[res.PID.idxmax()]\n",
    "        best_gene = best_hit.subject\n",
    "        res2 = bbh2[bbh2.gene==best_gene]\n",
    "        if len(res2)==0:\n",
    "            continue\n",
    "        best_hit2 = res2.loc[res2.PID.idxmax()]\n",
    "        best_gene2 = best_hit2.subject\n",
    "        if g==best_gene2:\n",
    "            best_hit['BBH'] = '<=>'\n",
    "        else:\n",
    "            best_hit['BBH'] = '->'\n",
    "        out=pd.concat([out, pd.DataFrame(best_hit).transpose()])\n",
    "    \n",
    "    #Save the final file to a designated CSV file    \n",
    "    out.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh/CP016622.1_vs_CP016552.1.txt\n",
      "blasting CP016622.1 vs CP016552.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016552.1.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP016552.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP016552.1_vs_CP016622.1.txt\n",
      "blasting CP016552.1 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP016552.1.fa -out bbh/CP016552.1_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP016552.1\n",
      "bbh/CP016622.1_vs_CP020030.1.txt\n",
      "blasting CP016622.1 vs CP020030.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP020030.1.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP020030.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP020030.1_vs_CP016622.1.txt\n",
      "blasting CP020030.1 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP020030.1.fa -out bbh/CP020030.1_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP020030.1\n",
      "bbh/CP016622.1_vs_CP012712.1.txt\n",
      "blasting CP016622.1 vs CP012712.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP012712.1.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP012712.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP012712.1_vs_CP016622.1.txt\n",
      "blasting CP012712.1 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP012712.1.fa -out bbh/CP012712.1_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP012712.1\n",
      "bbh/CP016622.1_vs_CP002835.1.txt\n",
      "blasting CP016622.1 vs CP002835.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP002835.1.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP002835.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP002835.1_vs_CP016622.1.txt\n",
      "blasting CP002835.1 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP002835.1.fa -out bbh/CP002835.1_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP002835.1\n",
      "bbh/CP016622.1_vs_CP001638.txt\n",
      "blasting CP016622.1 vs CP001638\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP001638.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP001638.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP001638_vs_CP016622.1.txt\n",
      "blasting CP001638 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP001638.fa -out bbh/CP001638_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP001638\n",
      "bbh/CP016622.1_vs_CP008903.1.txt\n",
      "blasting CP016622.1 vs CP008903.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP008903.1.fa -query prots/CP016622.1.fa -out bbh/CP016622.1_vs_CP008903.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "bbh/CP008903.1_vs_CP016622.1.txt\n",
      "blasting CP008903.1 vs CP016622.1\n",
      "running blastp with following command line...\n",
      "blastp -db prots/CP016622.1.fa -query prots/CP008903.1.fa -out bbh/CP008903.1_vs_CP016622.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "parsing BBHs for CP016622.1 CP008903.1\n"
     ]
    }
   ],
   "source": [
    "# Execute the BLAST for each target strain against the reference strain, save results to 'bbh' i.e. \"bidirectional best\n",
    "# hits\" folder to create\n",
    "# homology matrix\n",
    "\n",
    "for strain in targetStrainIDs:\n",
    "    get_bbh(referenceStrainID,strain, in_folder='bbh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the BLAST Results into one Homology Matrix of the Reconstruction Genes\n",
    "\n",
    "For the homology matrix, we only focus on genes that are present in the reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh\\CP016622.1_vs_CP001638_parsed.csv (0, 1)\n",
      "bbh\\CP016622.1_vs_CP002835.1_parsed.csv (0, 1)\n",
      "bbh\\CP016622.1_vs_CP008903.1_parsed.csv (0, 1)\n",
      "bbh\\CP016622.1_vs_CP012712.1_parsed.csv (0, 1)\n",
      "bbh\\CP016622.1_vs_CP016552.1_parsed.csv (0, 1)\n",
      "bbh\\CP016622.1_vs_CP020030.1_parsed.csv (0, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load all the BLAST files between the reference strain and target strains\n",
    "\n",
    "blast_files=glob('%s/*_parsed.csv'%'bbh')\n",
    "\n",
    "for blast in blast_files:\n",
    "    bbh=pd.read_csv(blast)\n",
    "    print (blast,bbh.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the base reconstruction to designate the list of genes within the model\n",
    "model = cobra.io.read_sbml_model('../../../model/g-thermo.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listGeneIDs=[]\n",
    "for gene in model.genes:\n",
    "    listGeneIDs.append(gene.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create 2 matrices of N, rows where N is the number of model genes and M columns where M is the number of target strains\n",
    "#One matrix will be populated with the PID results from the blasts and another with the mapping of gene locus tags\n",
    "\n",
    "ortho_matrix=pd.DataFrame(index=listGeneIDs,columns=targetStrainIDs)\n",
    "geneIDs_matrix=pd.DataFrame(index=listGeneIDs,columns=targetStrainIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse through each blast file and acquire pertinent information for each matrix for each of the base reconstruction genes\n",
    "for blast in blast_files:\n",
    "    bbh=pd.read_csv(blast)\n",
    "    listIDs=[]\n",
    "    listPID=[]\n",
    "    for r,row in ortho_matrix.iterrows():\n",
    "        try:\n",
    "            currentOrtholog=bbh[bbh['gene']==r].reset_index()\n",
    "            listIDs.append(currentOrtholog.iloc[0]['subject'])\n",
    "            listPID.append(currentOrtholog.iloc[0]['PID'])\n",
    "        except:\n",
    "            listIDs.append('None')\n",
    "            listPID.append(0)\n",
    "    for col in ortho_matrix.columns:\n",
    "        if col in blast:\n",
    "            ortho_matrix[col]=listPID\n",
    "            geneIDs_matrix[col]=listIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Similarity Threshold to Binarize  Homology Matrix to Presence/Absence Matrix\n",
    "In this step, choose a threshold for the PID to determine if a gene is a absent/present in the strain of interest. We can then convert the homology matrix generated above into a binarized presence/absence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutoriao, genes with a greater than 80% PID are considered present in the target strain genome \n",
    "# and consequently less than 80% are considered absent from the target strain genome\n",
    "for column in ortho_matrix:\n",
    "    ortho_matrix.loc[ortho_matrix[column]<=80.0,column]=0\n",
    "    ortho_matrix.loc[ortho_matrix[column]>80.0,column]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP000946.1</th>\n",
       "      <th>CU651637.1</th>\n",
       "      <th>CP002167.1</th>\n",
       "      <th>CU928163.2</th>\n",
       "      <th>CU928164.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b2551</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0870</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3368</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3500</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0945</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4467</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4468</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2979</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3916</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1260</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1261</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3426</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2242</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2241</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4054</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3281</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1692</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3041</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0025</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0844</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0446</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3812</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1662</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0421</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0662</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2683</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2682</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1821</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2164</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0577</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0465</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3291</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4159</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2924</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1330</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0808</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2247</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0597</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1870</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3116</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4093</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1206</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1516 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CP000946.1  CU651637.1  CP002167.1  CU928163.2  CU928164.2\n",
       "b2551         1.0         1.0         1.0         1.0         1.0\n",
       "b0870         1.0         1.0         1.0         1.0         1.0\n",
       "b3368         1.0         1.0         1.0         1.0         1.0\n",
       "b2436         1.0         1.0         1.0         1.0         1.0\n",
       "b3500         1.0         1.0         1.0         1.0         1.0\n",
       "b0945         1.0         1.0         1.0         1.0         1.0\n",
       "b4467         1.0         1.0         1.0         1.0         1.0\n",
       "b4468         1.0         1.0         1.0         1.0         1.0\n",
       "b2979         1.0         1.0         1.0         1.0         1.0\n",
       "b3916         1.0         1.0         1.0         1.0         1.0\n",
       "b1260         1.0         1.0         1.0         1.0         1.0\n",
       "b1261         1.0         1.0         1.0         1.0         1.0\n",
       "b3426         1.0         1.0         1.0         1.0         1.0\n",
       "b2242         1.0         1.0         1.0         1.0         1.0\n",
       "b2243         1.0         1.0         1.0         1.0         1.0\n",
       "b2241         1.0         1.0         1.0         1.0         1.0\n",
       "b4054         1.0         1.0         1.0         1.0         1.0\n",
       "b3770         1.0         1.0         1.0         1.0         1.0\n",
       "b3281         1.0         1.0         1.0         1.0         1.0\n",
       "b1692         1.0         1.0         1.0         1.0         1.0\n",
       "b0243         1.0         1.0         1.0         1.0         1.0\n",
       "b1613         1.0         1.0         1.0         1.0         1.0\n",
       "b0414         1.0         1.0         1.0         1.0         1.0\n",
       "b3041         1.0         1.0         1.0         1.0         1.0\n",
       "b0025         1.0         1.0         1.0         1.0         1.0\n",
       "b0844         1.0         1.0         1.0         1.0         1.0\n",
       "b0446         1.0         1.0         1.0         1.0         1.0\n",
       "b3812         1.0         1.0         1.0         1.0         1.0\n",
       "b1662         1.0         1.0         1.0         1.0         1.0\n",
       "b0421         1.0         1.0         1.0         1.0         1.0\n",
       "...           ...         ...         ...         ...         ...\n",
       "b4095         1.0         1.0         1.0         1.0         1.0\n",
       "b4092         1.0         1.0         1.0         1.0         1.0\n",
       "b2047         1.0         1.0         1.0         1.0         1.0\n",
       "b4106         1.0         1.0         1.0         1.0         1.0\n",
       "b4104         1.0         1.0         1.0         1.0         1.0\n",
       "b4105         1.0         1.0         1.0         1.0         1.0\n",
       "b0662         1.0         1.0         1.0         1.0         1.0\n",
       "b2906         1.0         1.0         1.0         1.0         1.0\n",
       "b1400         1.0         0.0         0.0         0.0         0.0\n",
       "b2683         1.0         1.0         1.0         1.0         1.0\n",
       "b2682         1.0         1.0         1.0         1.0         1.0\n",
       "b1821         1.0         1.0         1.0         1.0         1.0\n",
       "b2164         1.0         1.0         1.0         1.0         1.0\n",
       "b1616         0.0         1.0         1.0         1.0         1.0\n",
       "b1517         1.0         0.0         0.0         1.0         1.0\n",
       "b0577         1.0         1.0         1.0         1.0         1.0\n",
       "b0465         1.0         1.0         1.0         1.0         1.0\n",
       "b3291         1.0         1.0         1.0         1.0         1.0\n",
       "b4159         1.0         1.0         1.0         1.0         1.0\n",
       "b2924         1.0         1.0         1.0         1.0         1.0\n",
       "b1330         1.0         1.0         1.0         1.0         1.0\n",
       "b0808         1.0         1.0         1.0         1.0         1.0\n",
       "b2247         1.0         1.0         1.0         0.0         1.0\n",
       "b0597         1.0         1.0         1.0         1.0         1.0\n",
       "b1870         1.0         1.0         1.0         1.0         1.0\n",
       "b3116         1.0         1.0         1.0         1.0         1.0\n",
       "b2796         1.0         1.0         1.0         1.0         1.0\n",
       "b4093         1.0         1.0         1.0         1.0         1.0\n",
       "b3878         0.0         0.0         0.0         1.0         1.0\n",
       "b1206         1.0         1.0         1.0         1.0         1.0\n",
       "\n",
       "[1516 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ortho_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform BLASTn to check unannotated open reading frames to guide manual curation \n",
    "At this juncture it may be useful to execute a supplementary nucleotide BLAST to check for unannotated genes, results here become candidates for manual curation. In this tutorial we retain unannotated genes that pass the threhsold for\n",
    "similarity and contain no premature stop codons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to generate FNA from the GBK files\n",
    "def gbk2fasta(gbk_filename):\n",
    "    faa_filename = '.'.join(gbk_filename.split('.')[:-1])+'.fna'\n",
    "    input_handle  = open(gbk_filename, \"r\")\n",
    "    output_handle = open(faa_filename, \"w\")\n",
    "\n",
    "    for seq_record in SeqIO.parse(input_handle, \"genbank\") :\n",
    "        print (\"Converting GenBank record %s\" % seq_record.id)\n",
    "        output_handle.write(\">%s %s\\n%s\\n\" % (\n",
    "               seq_record.id,\n",
    "               seq_record.description,\n",
    "               seq_record.seq))\n",
    "\n",
    "    output_handle.close()\n",
    "    input_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to run the BLASTn\n",
    "def run_blastn(seq, db,outfmt=6,evalue=0.001,threads=1):\n",
    "    import os\n",
    "    out = 'nucl/'+seq+'_vs_'+db+'.txt'\n",
    "    seq = 'nucl/'+seq+'.fa'\n",
    "    db = 'genomes/'+db+'.fna'\n",
    "    \n",
    "    cmd_line='blastn -db %s -query %s -out %s -evalue %s -outfmt %s -num_threads %i' \\\n",
    "    %(db, seq, out, evalue, outfmt, threads)\n",
    "    \n",
    "    print ('running blastn with following command line...')\n",
    "    print (cmd_line)\n",
    "    os.system(cmd_line)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making blast db with following command line...\n",
      "makeblastdb -in genomes/CP000946.1.fna -dbtype nucl\n",
      "making blast db with following command line...\n",
      "makeblastdb -in genomes/CU651637.1.fna -dbtype nucl\n",
      "making blast db with following command line...\n",
      "makeblastdb -in genomes/CP002167.1.fna -dbtype nucl\n",
      "making blast db with following command line...\n",
      "makeblastdb -in genomes/CU928163.2.fna -dbtype nucl\n",
      "making blast db with following command line...\n",
      "makeblastdb -in genomes/CU928164.2.fna -dbtype nucl\n"
     ]
    }
   ],
   "source": [
    "# make nucleotide sequence databases \n",
    "for strain in targetStrainIDs:\n",
    "    make_blast_db(strain,folder='genomes',db_type='nucl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting GenBank record CP000946.1\n",
      "Converting GenBank record CU651637.1\n",
      "Converting GenBank record CP002167.1\n",
      "Converting GenBank record CU928163.2\n",
      "Converting GenBank record CU928164.2\n"
     ]
    }
   ],
   "source": [
    "# convert genbank files to fna files for strains of interest\n",
    "for strain in targetStrainIDs:\n",
    "    gbk2fasta('genomes/'+strain+'.gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running blastn with following command line...\n",
      "blastn -db genomes/CP000946.1.fna -query nucl/NC_000913.3.fa -out nucl/NC_000913.3_vs_CP000946.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "running blastn with following command line...\n",
      "blastn -db genomes/CU651637.1.fna -query nucl/NC_000913.3.fa -out nucl/NC_000913.3_vs_CU651637.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "running blastn with following command line...\n",
      "blastn -db genomes/CP002167.1.fna -query nucl/NC_000913.3.fa -out nucl/NC_000913.3_vs_CP002167.1.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "running blastn with following command line...\n",
      "blastn -db genomes/CU928163.2.fna -query nucl/NC_000913.3.fa -out nucl/NC_000913.3_vs_CU928163.2.txt -evalue 0.001 -outfmt 6 -num_threads 1\n",
      "running blastn with following command line...\n",
      "blastn -db genomes/CU928164.2.fna -query nucl/NC_000913.3.fa -out nucl/NC_000913.3_vs_CU928164.2.txt -evalue 0.001 -outfmt 6 -num_threads 1\n"
     ]
    }
   ],
   "source": [
    "# perform uni-directional BLASTn hit\n",
    "genome_blast_res=[]\n",
    "for strain in targetStrainIDs:\n",
    "    res = run_blastn(referenceStrainID,strain)\n",
    "    genome_blast_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to parse through the nucleotide BLAST results and form one matrix of all the results\n",
    "def parse_nucl_blast(infile):\n",
    "    cols = ['gene', 'subject', 'PID', 'alnLength', 'mismatchCount', 'gapOpenCount', 'queryStart', 'queryEnd', 'subjectStart', 'subjectEnd', 'eVal', 'bitScore']\n",
    "    data = pd.read_csv(infile, sep='\\t', names=cols)\n",
    "    data = data[(data['PID']>80) & (data['alnLength']>0.8*data['queryEnd'])]\n",
    "    data2=data.groupby('gene').first()\n",
    "    return data2.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse the nucleotide blast matrix \n",
    "na_matrix=pd.DataFrame()\n",
    "for file in genome_blast_res:\n",
    "    genes =parse_nucl_blast(file)\n",
    "    name ='.'.join(file.split('_')[-1].split('.')[:-1])\n",
    "    na_matrix = na_matrix.append(genes[['gene','subject','PID']])\n",
    "na_matrix = pd.pivot_table(na_matrix, index='gene', columns='subject',values='PID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subject</th>\n",
       "      <th>CP000946.1</th>\n",
       "      <th>CP002167.1</th>\n",
       "      <th>CU651637.1</th>\n",
       "      <th>CU928163.2</th>\n",
       "      <th>CU928164.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b0002</th>\n",
       "      <td>97.97</td>\n",
       "      <td>97.69</td>\n",
       "      <td>97.56</td>\n",
       "      <td>98.78</td>\n",
       "      <td>98.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0003</th>\n",
       "      <td>98.71</td>\n",
       "      <td>98.29</td>\n",
       "      <td>98.29</td>\n",
       "      <td>98.29</td>\n",
       "      <td>99.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0004</th>\n",
       "      <td>98.99</td>\n",
       "      <td>98.06</td>\n",
       "      <td>97.75</td>\n",
       "      <td>98.21</td>\n",
       "      <td>97.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0005</th>\n",
       "      <td>99.66</td>\n",
       "      <td>91.09</td>\n",
       "      <td>97.03</td>\n",
       "      <td>97.98</td>\n",
       "      <td>98.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0006</th>\n",
       "      <td>99.23</td>\n",
       "      <td>97.68</td>\n",
       "      <td>97.55</td>\n",
       "      <td>98.46</td>\n",
       "      <td>98.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subject  CP000946.1  CP002167.1  CU651637.1  CU928163.2  CU928164.2\n",
       "gene                                                               \n",
       "b0002         97.97       97.69       97.56       98.78       98.86\n",
       "b0003         98.71       98.29       98.29       98.29       99.68\n",
       "b0004         98.99       98.06       97.75       98.21       97.82\n",
       "b0005         99.66       91.09       97.03       97.98       98.73\n",
       "b0006         99.23       97.68       97.55       98.46       98.58"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine unnannotated open reading frames\n",
    "We compare the results from BLASTp and BLASTn and record any inconsistencies between the two matrices due to missing annotation. This result is then saved to guide future manual curation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract the sequence from fna file \n",
    "def extract_seq(g, contig, start, end):\n",
    "    from Bio import SeqIO\n",
    "    handle = open(g)\n",
    "    records = SeqIO.parse(handle, \"fasta\")\n",
    "    \n",
    "    for record in records:\n",
    "        if record.name==contig:\n",
    "            if end>start:\n",
    "                section = record[start:end]\n",
    "            else:\n",
    "                section = record[end-1:start+1].reverse_complement()\n",
    "                \n",
    "            seq = str(section.seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define updated matrices that will include genes based on sequence evidence that were missing due to lack of annotation\n",
    "ortho_matrix_w_unannotated = ortho_matrix.copy()\n",
    "geneIDs_matrix_w_unannotated = geneIDs_matrix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define matrix of the BLASTn results for all the pertinent model genes\n",
    "nonModelGenes=[]\n",
    "for g in na_matrix.index:\n",
    "    if g not in listGeneIDs:\n",
    "        nonModelGenes.append(g)\n",
    "\n",
    "na_model_genes=na_matrix.drop(nonModelGenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP000946.1 {'b4321', 'b0973', 'b0516', 'b3577', 'b1621', 'b1817', 'b1616', 'b2483', 'b0030', 'b4513', 'b1771'}\n",
      "CU651637.1 {'b4321', 'b2930', 'b2344', 'b2690', 'b2430', 'b4513', 'b1588', 'b0150'}\n",
      "CP002167.1 {'b4321', 'b2930', 'b4086', 'b1587', 'b0936', 'b2519', 'b2430', 'b3715', 'b4513', 'b3579', 'b1897'}\n",
      "CU928163.2 {'b4513', 'b4515'}\n",
      "CU928164.2 {'b4513', 'b4515'}\n"
     ]
    }
   ],
   "source": [
    "#For each strain in the ortho_matrix, identify genes that meet threshold of SEQ similarity, but missing from\n",
    "#annotated ORFS. Additionally, look at the sequence to ensure that these cases do not have early stop codons indicating\n",
    "#nonfunctional even if the NA seqs meet the threshold\n",
    "\n",
    "pseudogenes = {}\n",
    "\n",
    "for c in ortho_matrix.columns:\n",
    "    \n",
    "    orfs = ortho_matrix[c]\n",
    "    genes = na_model_genes[c]\n",
    "    # All the Model Genes that met the BLASTp Requirements\n",
    "    orfs2 = orfs[orfs==1].index.tolist()\n",
    "    # All the Model Genes based off of BLASTn similarity above threshold of 80\n",
    "    genes2 = genes[genes>=80].index.tolist()\n",
    "    # By Definition find the genes that pass sequence threshold but were NOT in annotated ORFs:\n",
    "    unannotated = set(genes2) -set(orfs2)\n",
    "    \n",
    "    # Obtain sequences of this list to check for premature stop codons:\n",
    "    data = 'nucl/NC_000913.3_vs_%s.txt'%c\n",
    "    cols = ['gene', 'subject', 'PID', 'alnLength', 'mismatchCount', 'gapOpenCount', 'queryStart', 'queryEnd', 'subjectStart', 'subjectEnd', 'eVal', 'bitScore']\n",
    "    data = pd.read_csv(data, sep='\\t', names=cols)\n",
    "    #\n",
    "    pseudogenes[c] = {}\n",
    "    unannotated_data = data[data['gene'].isin(list(unannotated))]\n",
    "    for i in unannotated_data.index:\n",
    "        gene = data.loc[i,'gene']\n",
    "        contig = data.loc[i,'subject'] \n",
    "        start = data.loc[i,'subjectStart']\n",
    "        end = data.loc[i,'subjectEnd']\n",
    "        seq = extract_seq('genomes/%s.fna'%c,contig, start, end)\n",
    "        # check for early stop codons - these are likely nonfunctional and shouldn't be included\n",
    "        if '*' in seq:\n",
    "            print (seq)\n",
    "            pseudogenes[c][gene]=seq\n",
    "            # Remove the gene from list of unannotated genes\n",
    "            unannotated-set([gene])\n",
    "            \n",
    "    \n",
    "    print (c, unannotated)\n",
    "    \n",
    "    # For pertinent genes, retain those based off of nucleotide similarity within the orthology matrix and geneIDs matrix\n",
    "    ortho_matrix_w_unannotated.loc[unannotated,c]=1\n",
    "    for g in unannotated:\n",
    "        geneIDs_matrix_w_unannotated.loc[g,c] = '%s_ortholog'%g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Presence/Absence Matrix and geneIDs Matrix for future use\n",
    "ortho_matrix_w_unannotated.to_csv('ortho_matrix.csv')\n",
    "geneIDs_matrix_w_unannotated.to_csv('geneIDs_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
